{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello World!\n",
    "This notebook describes the effort to cleanup and cluster a Habits dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de-duplicate : based on email i'd\n",
    "               \n",
    "Clustering the Data:\n",
    "two methods - \n",
    "\n",
    "A) cluster the data  and see how many clusters are there: used **MeanShift method**\n",
    "\n",
    "\n",
    "B) three bins : \"signed up not used\" aka less than 2 days, \"completed not beyond 1 week\" aka less than 8 days, \"everyone else\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking around the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple function to read in the user data file.\n",
    "# the argument parse_dates takes in a list of colums, which are to be parsed as date format\n",
    "user_data_raw_csv = pd.read_csv(\"/home/eyebell/local_bin/janacare/janCC/datasets/Habits-Data_upto-7th-May.csv\",\\\n",
    "                            parse_dates = [-3, -2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the pyexcel module\n",
    "#import pyexcel as pe\n",
    "#from pyexcel.ext import xls\n",
    "\n",
    "# load the file\n",
    "#records = pe.get_records(file_name=\"/home/eyebell/local_bin/janacare/datasets/Habits-Data_upto-7th-May.xls\")\n",
    "#len(records)\n",
    "#for record in records:\n",
    "    #print record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data metrics\n",
    "user_data_raw_csv.shape # Rows , colums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data metrics\n",
    "user_data_raw_csv.dtypes # data type of colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data_to_clean = user_data_raw_csv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some basic statistical information on the data\n",
    "#user_data_to_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section of looking around, I saw that a lot of rows do not have any values or have garbage values(see first row of the table above).\n",
    "This can cause errors when computing anything using the values in these rows, hence a clean up is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a the coulums *last_activity* and *first_login* are empty then drop the corresponding row !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets check the health of the data set\n",
    "user_data_to_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is visible from the last column (*age_on_platform*) data type, Pandas is not recognising it as date type format. \n",
    "This will make things difficult, so I delete this particular column and add a new one.\n",
    "Since the data in *age_on_platform* can be recreated by doing *age_on_platform* = *last_activity* - *first_login* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But on eyeballing I noticed some, cells of column *first_login* have greater value than corresponding cell of *last_activity*. These cells need to be swapped, since its not possible to have *first_login* > *last_activity*\n",
    "Finally the columns *first_login*, *last_activity* have missing values, as evident from above table. Since this is time data, that in my opinion should not be imputed, we will drop/delete the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run a loop through the data frame and check each row for this anamoly, if found drop,\n",
    "# this is being done ONLY for selected columns\n",
    "\n",
    "import datetime\n",
    "\n",
    "swapped_count = 0\n",
    "first_login_count = 0\n",
    "last_activity_count = 0\n",
    "email_count = 0\n",
    "userid_count = 0\n",
    "\n",
    "for index, row in user_data_to_clean.iterrows():        \n",
    "        if row.last_activity == pd.NaT or row.last_activity != row.last_activity:\n",
    "            last_activity_count = last_activity_count + 1\n",
    "            #print row.last_activity\n",
    "            user_data_to_clean.drop(index, inplace=True)\n",
    "\n",
    "        elif row.first_login > row.last_activity:\n",
    "            user_data_to_clean.drop(index, inplace=True)\n",
    "            swapped_count = swapped_count + 1\n",
    "\n",
    "        elif row.first_login != row.first_login or row.first_login == pd.NaT:\n",
    "            user_data_to_clean.drop(index, inplace=True)\n",
    "            first_login_count = first_login_count + 1\n",
    "\n",
    "        elif row.email != row.email: #or row.email == '' or row.email == ' ':\n",
    "            user_data_to_clean.drop(index, inplace=True)\n",
    "            email_count = email_count + 1\n",
    "\n",
    "        elif row.user_id != row.user_id:\n",
    "            user_data_to_clean.drop(index, inplace=True)\n",
    "            userid_count = userid_count + 1\n",
    "\n",
    "print \"last_activity_count=%d\\tswapped_count=%d\\tfirst_login_count=%d\\temail_count=%d\\tuserid_count=%d\" \\\n",
    "% (last_activity_count, swapped_count, first_login_count, email_count, userid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data_to_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new column 'age_on_platform' which has the corresponding value in date type format\n",
    "user_data_to_clean[\"age_on_platform\"] = user_data_to_clean[\"last_activity\"] - user_data_to_clean[\"first_login\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data_to_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate if email i'd is correctly formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from validate_email import validate_email\n",
    "\n",
    "email_count_invalid = 0\n",
    "for index, row in user_data_to_clean.iterrows():        \n",
    "        if not validate_email(row.email):\n",
    "            #print row.email\n",
    "            user_data_to_clean.drop(index, inplace=True)\n",
    "            email_count_invalid = email_count_invalid + 1\n",
    "\n",
    "print \"Number of email-id invalid: %d\" % (email_count_invalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the result of last operation \n",
    "user_data_to_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data_to_deDuplicate = user_data_to_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data_deDuplicateD = user_data_to_deDuplicate.loc[~user_data_to_deDuplicate.email.str.strip().duplicated()]\n",
    "len(user_data_deDuplicateD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data_deDuplicateD.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now its time to convert the timedelta64 column named age_on_platform\n",
    "def convert_timedelta64_to_sec(td64):\n",
    "    ts = (td64 / np.timedelta64(1, 's'))\n",
    "    return ts\n",
    "\n",
    "user_data_deDuplicateD_timedelta64_converted = user_data_deDuplicateD.copy()\n",
    "user_data_deDuplicateD_timedelta64_converted['age_on_platform'] = user_data_deDuplicateD_timedelta64_converted['age_on_platform'].apply(convert_timedelta64_to_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clustering using Mean shift\n",
    "\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "#x = [1,1,5,6,1,5,10,22,23,23,50,51,51,52,100,112,130,500,512,600,12000,12230]\n",
    "x = pd.Series(user_data_deDuplicateD_timedelta64_converted['age_on_platform'])\n",
    "\n",
    "X = np.array(zip(x,np.zeros(len(x))), dtype=np.int)\n",
    "bandwidth = estimate_bandwidth(X, quantile=0.2)\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(X)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "for k in range(n_clusters_):\n",
    "    my_members = labels == k\n",
    "    print \"cluster {0} : lenght = {1}\".format(k, len(X[my_members, 0]))\n",
    "    #print \"cluster {0}: {1}\".format(k, X[my_members, 0])\n",
    "    cluster_sorted = sorted(X[my_members, 0])\n",
    "    print \"cluster {0} : Max = {2} days & Min {1} days\".format(k, cluster_sorted[0]*1.15741e-5, cluster_sorted[-1]*1.15741e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clustering using Kmeans, not working\n",
    "'''\n",
    "y = [1,1,5,6,1,5,10,22,23,23,50,51,51,52,100,112,130,500,512,600,12000,12230]\n",
    "y_float = map(float, y)\n",
    "x = range(len(y))\n",
    "x_float = map(float, x)\n",
    "\n",
    "m = np.matrix([x_float, y_float]).transpose()\n",
    "\n",
    "\n",
    "from scipy.cluster.vq import kmeans\n",
    "kclust = kmeans(m, 5)\n",
    "\n",
    "kclust[0][:, 0]\n",
    "\n",
    "assigned_clusters = [abs(cluster_indices - e).argmin() for e in x]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning based on **age_on_platform** \n",
    "bin1 = 0 to 1 days\n",
    "\n",
    "bin2 = 2 to 8 days\n",
    "\n",
    "bin3 = 8 days and beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data_binned = user_data_deDuplicateD.copy()\n",
    "\n",
    "for index, row in user_data_deDuplicateD.iterrows():\n",
    "    if row[\"age_on_platform\"] < np.timedelta64(2, 'D'):\n",
    "        user_data_binned.set_value(index, 'bin', 1)\n",
    "        \n",
    "    elif row[\"age_on_platform\"] >= np.timedelta64(2, 'D') and row[\"age_on_platform\"] < np.timedelta64(8, 'D'):\n",
    "        user_data_binned.set_value(index, 'bin', 2)    \n",
    "        \n",
    "    elif row[\"age_on_platform\"] >= np.timedelta64(8, 'D'):\n",
    "        user_data_binned.set_value(index, 'bin', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of users with age_on_platform less than 2 days = %d\" % len(user_data_binned[user_data_binned.bin == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of users with age_on_platform greater than or equal to 2 days and less than 8 days = %d\" % len(user_data_binned[user_data_binned.bin == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of users with age_on_platform greater than 8 days = %d\" % len(user_data_binned[user_data_binned.bin == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data_binned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save dataframe with binned values as CSV\n",
    "user_data_binned.to_csv('user_data_binned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
